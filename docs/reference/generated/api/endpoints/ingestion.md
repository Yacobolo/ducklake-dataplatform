<!-- Code generated by cmd/docsgen. DO NOT EDIT. -->

# Ingestion Endpoints

Data ingestion via upload, commit, and external file loading.

## `POST /catalogs/{catalogName}/schemas/{schemaName}/tables/{tableName}/ingestion/commit`

Register uploaded Parquet files in DuckLake

Registers previously uploaded files (from upload-url) in the DuckLake catalog. DuckLake validates schema compatibility, extracts column statistics, and registers files atomically. Requires INSERT privilege on the target table.

- Operation ID: `commitTableIngestion`

### Path Parameters

| Name | Type | Required | Description |
| --- | --- | --- | --- |
| `catalogName` | `string` | `true` | Name of the catalog. |
| `schemaName` | `string` | `true` | Name of the database schema. |
| `tableName` | `string` | `true` | Name of the table. |

### Request Body

- Required: `true`
- Content types: `application/json`

### Responses

| Code | Description |
| --- | --- |
| `200` | Ingestion result |
| `400` | Invalid request parameters or malformed request body. |
| `401` | Authentication credentials are missing or invalid. |
| `403` | Insufficient privileges to perform this operation. |
| `404` | The requested resource was not found. |
| `429` | Rate limit exceeded. Retry after the indicated duration. |
| `500` | An unexpected internal server error occurred. |

## `POST /catalogs/{catalogName}/schemas/{schemaName}/tables/{tableName}/ingestion/load`

Register existing S3 files in DuckLake

Registers existing S3 files or globs in the DuckLake catalog. Paths without an s3:// prefix are treated as relative to the lake data path. DuckLake validates schema compatibility, extracts column statistics, and registers files atomically. Requires INSERT privilege on the target table.

- Operation ID: `loadTableExternalFiles`

### Path Parameters

| Name | Type | Required | Description |
| --- | --- | --- | --- |
| `catalogName` | `string` | `true` | Name of the catalog. |
| `schemaName` | `string` | `true` | Name of the database schema. |
| `tableName` | `string` | `true` | Name of the table. |

### Request Body

- Required: `true`
- Content types: `application/json`

### Responses

| Code | Description |
| --- | --- |
| `200` | Ingestion result |
| `400` | Invalid request parameters or malformed request body. |
| `401` | Authentication credentials are missing or invalid. |
| `403` | Insufficient privileges to perform this operation. |
| `404` | The requested resource was not found. |
| `429` | Rate limit exceeded. Retry after the indicated duration. |
| `500` | An unexpected internal server error occurred. |

## `POST /catalogs/{catalogName}/schemas/{schemaName}/tables/{tableName}/ingestion/upload-url`

Get a presigned URL for uploading a Parquet file

Returns a presigned PUT URL that the client can use to upload a Parquet file directly to S3. The file can then be registered via the commit endpoint. Requires INSERT privilege on the target table.

- Operation ID: `createUploadUrl`

### Path Parameters

| Name | Type | Required | Description |
| --- | --- | --- | --- |
| `catalogName` | `string` | `true` | Name of the catalog. |
| `schemaName` | `string` | `true` | Name of the database schema. |
| `tableName` | `string` | `true` | Name of the table. |

### Request Body

- Required: `true`
- Content types: `application/json`

### Responses

| Code | Description |
| --- | --- |
| `200` | Presigned upload URL |
| `400` | Invalid request parameters or malformed request body. |
| `401` | Authentication credentials are missing or invalid. |
| `403` | Insufficient privileges to perform this operation. |
| `404` | The requested resource was not found. |
| `429` | Rate limit exceeded. Retry after the indicated duration. |
| `500` | An unexpected internal server error occurred. |

