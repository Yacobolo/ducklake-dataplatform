# External Tables Implementation Plan

## Overview

Add read-only external tables that reference existing Parquet/CSV files on S3 without importing data. External tables are stored as DuckDB VIEWs backed by `read_parquet()`/`read_csv()`, with metadata in an application-owned SQLite table.

## Architecture Decisions

1. **DuckDB representation**: External tables are **VIEWs** — `CREATE VIEW lake."schema"."table" AS SELECT * FROM read_parquet([...])`. DuckLake doesn't know about them.
2. **Metadata storage**: New `external_tables` + `external_table_columns` SQLite tables (app-owned, managed via sqlc).
3. **ID space**: External table IDs are offset by `10,000,000` to avoid collision with DuckLake's auto-increment table IDs. `IsExternalTableID(id)` checks `id >= 10_000_000`.
4. **Read-only enforcement**: Engine blocks INSERT/UPDATE/DELETE on external tables.
5. **Column discovery**: Columns are auto-discovered from Parquet schema via `DESCRIBE SELECT * FROM read_parquet(...)` if not provided.
6. **VIEW restoration**: VIEWs are lost on DuckDB restart — a startup function recreates them from metadata.
7. **Credential resolution**: Source path must fall under a registered External Location; DuckDB secrets are already installed at startup.

## Implementation Order

| # | Step | Files | Effort |
|---|------|-------|--------|
| 1 | Migration + sqlc queries | 2 new | Low |
| 2 | Domain types + interfaces | 2 new, 2 modified | Low |
| 3 | DDL builder functions | 1 modified + tests | Low |
| 4 | External table repository | 1 new + tests | Medium |
| 5 | Catalog repository changes | 1 modified | Medium |
| 6 | Authorization changes | 1 modified | Medium |
| 7 | Engine DML blocking | 1 modified | Low |
| 8 | Service branching | 1 modified | Low |
| 9 | OpenAPI + codegen + handler | 3 modified | Medium |
| 10 | Startup wiring + VIEW restore | 1 modified | Low |
| 11 | Tests (unit + integration) | 2-3 new/modified | Medium |

---

## Step 1: Migration + sqlc Queries

### `internal/db/migrations/021_create_external_tables.sql` (NEW)

```sql
-- +goose Up
CREATE TABLE IF NOT EXISTS external_tables (
    id            INTEGER PRIMARY KEY AUTOINCREMENT,
    schema_name   TEXT NOT NULL,
    table_name    TEXT NOT NULL,
    file_format   TEXT NOT NULL DEFAULT 'parquet',
    source_path   TEXT NOT NULL,
    location_name TEXT NOT NULL,
    comment       TEXT NOT NULL DEFAULT '',
    owner         TEXT NOT NULL DEFAULT '',
    created_at    TEXT NOT NULL DEFAULT (datetime('now')),
    updated_at    TEXT NOT NULL DEFAULT (datetime('now')),
    deleted_at    TEXT,
    UNIQUE(schema_name, table_name)
);

CREATE TABLE IF NOT EXISTS external_table_columns (
    id                INTEGER PRIMARY KEY AUTOINCREMENT,
    external_table_id INTEGER NOT NULL REFERENCES external_tables(id) ON DELETE CASCADE,
    column_name       TEXT NOT NULL,
    column_type       TEXT NOT NULL,
    position          INTEGER NOT NULL,
    UNIQUE(external_table_id, column_name)
);

-- +goose Down
DROP TABLE IF EXISTS external_table_columns;
DROP TABLE IF EXISTS external_tables;
```

### `internal/db/queries/external_tables.sql` (NEW)

sqlc queries for CRUD on `external_tables` and `external_table_columns`:
- `CreateExternalTable` — INSERT RETURNING *
- `GetExternalTableByName` — by schema_name + table_name, `deleted_at IS NULL`
- `GetExternalTableByID` — by id, `deleted_at IS NULL`
- `GetExternalTableByTableName` — by table_name only (for engine lookup), `deleted_at IS NULL`
- `ListExternalTables` — by schema_name with LIMIT/OFFSET, `deleted_at IS NULL`
- `CountExternalTables` — COUNT by schema_name, `deleted_at IS NULL`
- `SoftDeleteExternalTable` — SET `deleted_at = datetime('now')`
- `SoftDeleteExternalTablesBySchema` — bulk soft-delete by schema_name
- `UpdateExternalTable` — conditional comment/owner update
- `InsertExternalTableColumn` — INSERT column
- `ListExternalTableColumns` — by external_table_id ORDER BY position
- `DeleteExternalTableColumns` — DELETE by external_table_id
- `ListAllExternalTables` — all non-deleted (for startup VIEW restore)

Then run: `task sqlc` and `task migrate-up`

---

## Step 2: Domain Types + Interfaces

### `internal/domain/external_table.go` (NEW, ~55 lines)

```go
type ExternalTableRecord struct {
    ID, SchemaName, TableName, FileFormat, SourcePath, LocationName, Comment, Owner string/int64/time.Time
    Columns []ExternalTableColumn
    DeletedAt *time.Time
}

type ExternalTableColumn struct {
    ID, ExternalTableID int64
    ColumnName, ColumnType string
    Position int
}

const ExternalTableIDOffset int64 = 10_000_000

func (et *ExternalTableRecord) EffectiveTableID() int64
func IsExternalTableID(tableID int64) bool
func ExternalTableRawID(tableID int64) int64
```

### `internal/domain/catalog.go` (MODIFY)

Add constants:
```go
const (
    TableTypeManaged  = "MANAGED"
    TableTypeExternal = "EXTERNAL"
)
```

Extend `CreateTableRequest`:
```go
type CreateTableRequest struct {
    Name         string
    Columns      []CreateColumnDef
    Comment      string
    TableType    string  // "MANAGED" or "EXTERNAL"
    SourcePath   string  // required for EXTERNAL
    FileFormat   string  // "parquet" (default) or "csv"
    LocationName string  // required for EXTERNAL
}
```

Extend `TableDetail`:
```go
// Add to TableDetail struct:
SourcePath   string
FileFormat   string
LocationName string
```

### `internal/domain/repository.go` (MODIFY)

Add `ExternalTableRepository` interface:
```go
type ExternalTableRepository interface {
    Create(ctx context.Context, et *ExternalTableRecord) (*ExternalTableRecord, error)
    GetByName(ctx context.Context, schemaName, tableName string) (*ExternalTableRecord, error)
    GetByID(ctx context.Context, id int64) (*ExternalTableRecord, error)
    GetByTableName(ctx context.Context, tableName string) (*ExternalTableRecord, error)
    List(ctx context.Context, schemaName string, page PageRequest) ([]ExternalTableRecord, int64, error)
    ListAll(ctx context.Context) ([]ExternalTableRecord, error)
    Delete(ctx context.Context, schemaName, tableName string) error
    DeleteBySchema(ctx context.Context, schemaName string) error
}
```

Add to `CatalogRepository` interface:
```go
CreateExternalTable(ctx context.Context, schemaName string, req CreateTableRequest, owner string) (*TableDetail, error)
```

Modify `AuthorizationService` interface — `LookupTableID` gains `isExternal` return:
```go
LookupTableID(ctx context.Context, tableName string) (tableID, schemaID int64, isExternal bool, err error)
```

---

## Step 3: DDL Builder

### `internal/ddl/builder.go` (MODIFY, +55 lines)

Add three functions:

```go
// CreateExternalTableView — generates:
//   CREATE VIEW lake."schema"."table" AS SELECT * FROM read_parquet(['s3://...'])
func CreateExternalTableView(schema, table, sourcePath, fileFormat string) (string, error)

// DropView — generates: DROP VIEW IF EXISTS lake."schema"."table"
func DropView(schema, table string) (string, error)

// DiscoverColumnsSQL — generates:
//   DESCRIBE SELECT * FROM read_parquet(['s3://...']) LIMIT 0
func DiscoverColumnsSQL(sourcePath, fileFormat string) (string, error)
```

Add tests in `internal/ddl/builder_test.go`:
- `TestCreateExternalTableView` (parquet, csv, invalid format, missing path)
- `TestDropView` (happy path, invalid identifiers)
- `TestDiscoverColumnsSQL` (parquet, csv)

---

## Step 4: External Table Repository

### `internal/db/repository/external_table.go` (NEW, ~200 lines)

```go
type ExternalTableRepo struct {
    db *sql.DB
    q  *dbstore.Queries
}

func NewExternalTableRepo(db *sql.DB) *ExternalTableRepo
var _ domain.ExternalTableRepository = (*ExternalTableRepo)(nil)
```

Methods: `Create`, `GetByName`, `GetByID`, `GetByTableName`, `List`, `ListAll`, `Delete`, `DeleteBySchema`. Each maps between sqlc-generated types and domain types, loads columns via `ListExternalTableColumns`.

### Tests in `internal/db/repository/external_table_test.go` (NEW)

Table-driven tests using real SQLite via `t.TempDir()`:
- Create + verify fields
- GetByName + GetByTableName
- List + Count
- Delete (soft-delete)
- Name conflict (unique constraint)

---

## Step 5: Catalog Repository Changes

### `internal/db/repository/catalog.go` (MODIFY, +120 lines)

**Add field and setter:**
```go
extRepo *ExternalTableRepo

func (r *CatalogRepo) SetExternalTableRepo(repo *ExternalTableRepo)
```

**Modify `GetTable` (~line 353):** After DuckLake lookup fails with `ErrNoRows`, fall back to `r.extRepo.GetByName()` and convert via `externalTableToDetail()`.

**Modify `ListTables` (~line 403):** After listing DuckLake tables, append external tables from `r.extRepo.List()`. Adjust total count. (v1: simple append — proper merged pagination is a follow-up.)

**Modify `DeleteTable` (~line 451):** Before DuckLake deletion, check if external table via `r.extRepo.GetByName()`. If found, call `deleteExternalTable()` instead.

**Modify `DeleteSchema` (~line 280):** Before dropping schema DDL, also delete external tables in the schema via `r.extRepo.DeleteBySchema()` + drop their VIEWs.

**New methods:**
- `CreateExternalTable(ctx, schemaName, req, owner)` — validates, discovers columns if needed, creates VIEW on DuckDB, persists metadata, stores catalog_metadata
- `externalTableToDetail(et, schemaName) *domain.TableDetail` — converts external table record to TableDetail
- `deleteExternalTable(ctx, schemaName, tableName, et)` — drops VIEW, soft-deletes metadata, cascades governance cleanup
- `discoverColumns(ctx, sourcePath, fileFormat) ([]domain.CreateColumnDef, error)` — runs DESCRIBE on DuckDB

---

## Step 6: Authorization Changes

### `internal/service/authorization.go` (MODIFY, +40 lines)

**Add field and setter:**
```go
extTableRepo domain.ExternalTableRepository

func (s *AuthorizationService) SetExternalTableRepo(repo domain.ExternalTableRepository)
```

**Modify `LookupTableID` (line 91):** Change return signature to `(tableID, schemaID int64, isExternal bool, err error)`. After DuckLake lookup fails, fall back to `s.extTableRepo.GetByTableName()`, resolve schema ID via `s.introspection.GetSchemaByName()`, return `(et.EffectiveTableID(), schemaID, true, nil)`.

**Modify `checkTablePrivilege` (line 171):** Currently calls `s.introspection.GetTable(ctx, tableID)` to get `schemaID`. For external tables (`IsExternalTableID(tableID)`), instead call `s.extTableRepo.GetByID(ExternalTableRawID(tableID))` then `s.introspection.GetSchemaByName(et.SchemaName)` to resolve `schemaID`. The rest of the privilege walk (USAGE gate → table grant → schema grant → catalog grant) stays the same.

**Update all callers of `LookupTableID`** to handle the new `isExternal` return value:
- `internal/engine/engine.go` line 81 — primary consumer
- Any other callers (check via LSP/grep)

---

## Step 7: Engine DML Blocking

### `internal/engine/engine.go` (MODIFY, +5 lines)

In `Query()` per-table loop (line ~80), after `LookupTableID`:

```go
tableID, _, isExternal, err := e.catalog.LookupTableID(ctx, tableName)
// ... existing error handling ...

// Block DML on external (read-only) tables
if isExternal && stmtType != sqlrewrite.StmtSelect {
    return nil, fmt.Errorf("access denied: table %q is read-only (EXTERNAL)", tableName)
}
```

---

## Step 8: Service Branching

### `internal/service/catalog.go` (MODIFY, +40 lines)

**Add field and setter:**
```go
func (s *CatalogService) SetExternalTableRepo(repo domain.ExternalTableRepository)
```

**Modify `CreateTable` (line 175):** Branch on `req.TableType`:
- `""` or `"MANAGED"` → existing flow (unchanged)
- `"EXTERNAL"` → new `createExternalTable()` method
- Other → `domain.ErrValidation("unsupported table_type...")`

**New `createExternalTable` method:**
1. Validate location exists via `s.locations.GetByName(ctx, req.LocationName)`
2. Validate `req.SourcePath` has prefix matching location's URL
3. Delegate to `s.repo.CreateExternalTable(ctx, schemaName, req, principal)`
4. Audit log: `CREATE_EXTERNAL_TABLE`

---

## Step 9: OpenAPI + Codegen + Handler

### `internal/api/openapi.yaml` (MODIFY)

**Modify `CreateTableApiRequest`:**
- Remove `columns` from `required` (only required for MANAGED)
- Add properties: `table_type` (enum: MANAGED, EXTERNAL), `source_path` (string), `file_format` (enum: parquet, csv), `location_name` (string)

**Modify `TableDetail` schema:**
- Add: `source_path`, `file_format`, `location_name` (optional string fields)

Then run: `task generate-api`

### `internal/api/handler.go` (MODIFY)

**Modify `CreateCatalogTable` (~line 679):** Map new API fields to domain request.

**Modify `tableDetailToAPI` (~line 1393):** Map `SourcePath`, `FileFormat`, `LocationName` to API response.

---

## Step 10: Startup Wiring + VIEW Restore

### `cmd/server/main.go` (MODIFY, +25 lines)

After repositories are created:
```go
extTableRepo := repository.NewExternalTableRepo(writeDB)
catalogRepo.SetExternalTableRepo(extTableRepo)
authSvc.SetExternalTableRepo(extTableRepo)
catalogSvc.SetExternalTableRepo(extTableRepo)
```

After DuckLake catalog is attached, restore VIEWs:
```go
func restoreExternalTableViews(ctx context.Context, duckDB *sql.DB, repo *repository.ExternalTableRepo) error
```
Lists all non-deleted external tables, creates `CREATE VIEW IF NOT EXISTS ...` for each. Errors are logged but not fatal (best-effort, like audit logging).

---

## Step 11: Tests

### Unit Tests

| File | Test Cases |
|------|-----------|
| `internal/ddl/builder_test.go` | `TestCreateExternalTableView`, `TestDropView`, `TestDiscoverColumnsSQL` |
| `internal/db/repository/external_table_test.go` (NEW) | CRUD, name conflicts, soft-delete |
| `internal/service/catalog_test.go` | `TestCreateExternalTable_*` (happy, missing location, path outside location, no privilege, missing source_path) |
| `internal/engine/engine_test.go` | `TestBlockDML_ExternalTable`, `TestAllowSelect_ExternalTable` |

### Integration Test

`test/integration/external_table_test.go` (NEW):
- Setup: seed credentials + external location
- Create external table (requires DuckLake + S3 or mocked Parquet file)
- Verify SELECT works
- Verify INSERT is blocked
- Verify table appears in ListTables with `table_type=EXTERNAL`
- Verify column auto-discovery
- Delete external table
- Verify audit logs

---

## Files Summary

### New Files (7)
| File | Est. Lines |
|------|-----------|
| `internal/db/migrations/021_create_external_tables.sql` | 25 |
| `internal/db/queries/external_tables.sql` | 60 |
| `internal/domain/external_table.go` | 55 |
| `internal/db/repository/external_table.go` | 200 |
| `internal/db/repository/external_table_test.go` | 250 |
| `internal/ddl/builder_test.go` (additions) | 80 |
| `test/integration/external_table_test.go` | 200 |

### Modified Files (10)
| File | Changes |
|------|---------|
| `internal/domain/catalog.go` | +15: constants, new fields on CreateTableRequest + TableDetail |
| `internal/domain/repository.go` | +15: ExternalTableRepository, CreateExternalTable on CatalogRepository, LookupTableID signature |
| `internal/ddl/builder.go` | +55: CreateExternalTableView, DropView, DiscoverColumnsSQL |
| `internal/db/repository/catalog.go` | +120: external table support in GetTable/ListTables/DeleteTable/DeleteSchema + new methods |
| `internal/service/authorization.go` | +40: LookupTableID fallback, checkTablePrivilege for external IDs |
| `internal/service/catalog.go` | +40: CreateTable branching, createExternalTable |
| `internal/engine/engine.go` | +5: DML blocking for external tables |
| `internal/api/openapi.yaml` | +30: new request/response fields |
| `internal/api/handler.go` | +25: map new fields |
| `cmd/server/main.go` | +25: wire repo, restore VIEWs |

### Regenerated Files
- `internal/api/types.gen.go`, `server.gen.go` — via `task generate-api`
- `internal/db/dbstore/*.sql.go` — via `task sqlc`

---

## Verification

```bash
# After each step:
task build && task vet && task test

# Run DDL builder tests:
go test -race -run "TestCreateExternalTableView|TestDropView|TestDiscoverColumns" ./internal/ddl/...

# Run repository tests:
go test -race -run "TestExternalTable" ./internal/db/repository/...

# Run service tests:
go test -race -run "TestCreateExternalTable" ./internal/service/...

# Run engine tests:
go test -race -run "TestBlockDML" ./internal/engine/...

# Full test suite:
task build && task vet && task test

# Integration tests (requires S3 + built extension):
task integration-test
```
